# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "checkworthiness.baml": "// Checkworthiness Assessment Schemas and Functions\n// Output classes with boolean fields for logprob-based confidence calculation\n\n// =============================================================================\n// Output Classes\n// =============================================================================\n\nclass CheckabilityOutput {\n  reasoning string @description(\"Step-by-step reasoning explaining why the claim is or is not checkable\")\n  confidence float @description(\"Confidence percentage (0-100) that the claim is checkable\")\n  is_checkable bool @description(\"True if the claim can be objectively verified against evidence\")\n}\n\nclass VerifiabilityOutput {\n  reasoning string @description(\"Step-by-step reasoning explaining the verifiability assessment\")\n  confidence float @description(\"Confidence percentage (0-100) that the claim is verifiable\")\n  is_verifiable bool @description(\"True if there is sufficient publicly available data to verify the claim\")\n}\n\nclass HarmSubScore {\n  confidence float @description(\"Confidence percentage (0-100) for this harm dimension\")\n  reasoning string @description(\"Reasoning for this specific harm dimension\")\n  is_harmful bool @description(\"True if this dimension of harm applies to the claim\")\n}\n\nclass HarmPotentialOutput {\n  reasoning string @description(\"Overall analysis of the claim's harm potential\")\n  confidence float @description(\"Overall confidence percentage (0-100) for harm potential\")\n  is_harmful bool @description(\"True if the claim has significant potential for societal harm\")\n  social_fragmentation HarmSubScore @description(\"Does this claim contribute to social fragmentation?\")\n  spurs_action HarmSubScore @description(\"Could this claim motivate harmful real-world behavior?\")\n  believability HarmSubScore @description(\"Is this claim presented in a way that seems credible?\")\n  exploitativeness HarmSubScore @description(\"Does this claim exploit vulnerabilities or emotions?\")\n}\n\n// =============================================================================\n// Checkability Function\n// =============================================================================\n\nfunction AssessCheckability(claim: string) -> CheckabilityOutput {\n  client OpenAI_GPT4o_Short\n  prompt #\"\n    You are an expert fact-checker evaluating whether claims can be objectively verified.\n\n    A claim is CHECKABLE if it makes a factual assertion that can be verified against evidence.\n\n    A claim is NOT CHECKABLE if it is:\n    - An OPINION: Subjective belief, preference, or value judgment (e.g., \"This is the best policy\")\n    - A PREDICTION: Statement about future events (e.g., \"The economy will crash\")\n    - VAGUE: Uses subjective terms without measurable criteria (e.g., \"Things are getting worse\")\n    - A QUESTION or COMMAND: Not an assertion (e.g., \"What about the economy?\")\n\n    EXAMPLES:\n    - \"Violent crime is down 10% in Texas\" → CHECKABLE (specific statistic, verifiable)\n    - \"I think the economy is doing well\" → NOT CHECKABLE (opinion)\n    - \"We will win the election\" → NOT CHECKABLE (prediction)\n    - \"Things have changed a lot\" → NOT CHECKABLE (vague, no measurable claim)\n\n    Analyze the following claim for checkability:\n    \"{{ claim }}\"\n\n    First, explain your reasoning step by step:\n    1. What type of statement is this? (factual assertion, opinion, prediction, vague, question/command)\n    2. Does it contain specific, measurable elements?\n    3. Could evidence confirm or refute this claim?\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// =============================================================================\n// Verifiability Function\n// =============================================================================\n\nfunction AssessVerifiability(claim: string) -> VerifiabilityOutput {\n  client OpenAI_GPT4o_Short\n  prompt #\"\n    You are an expert fact-checker evaluating whether claims can be practically verified using available evidence.\n\n    A claim is VERIFIABLE if:\n    - Public data sources exist (government statistics, academic research, official records)\n    - Reputable sources can confirm or refute it (news organizations, expert institutions)\n    - The evidence is accessible (not classified, not proprietary, not lost to history)\n\n    A claim is NOT VERIFIABLE or HARD TO VERIFY if:\n    - It refers to private conversations or undocumented events\n    - Required data is classified, proprietary, or inaccessible\n    - It's about subjective experiences that can't be externally confirmed\n    - The timeframe or specifics make verification impractical\n\n    EXAMPLES:\n    - \"The US GDP grew 3% in 2023\" → VERIFIABLE (government economic data available)\n    - \"He said something offensive in private\" → NOT VERIFIABLE (no public record)\n    - \"Crime rates in ancient Rome were high\" → HARD TO VERIFY (limited historical data)\n\n    Note: You are assessing WHETHER it can be verified, NOT whether it is true or false.\n\n    Analyze the following claim for verifiability:\n    \"{{ claim }}\"\n\n    First, explain your reasoning step by step:\n    1. What evidence would be needed to verify this claim?\n    2. Are such sources publicly available and accessible?\n    3. How difficult would verification be in practice?\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// =============================================================================\n// Harm Potential Function\n// =============================================================================\n\nfunction AssessHarmPotential(claim: string) -> HarmPotentialOutput {\n  client OpenAI_GPT4o_Long\n  prompt #\"\n    You are a misinformation risk analyst evaluating the potential societal harm of claims.\n\n    Assess harm potential across four dimensions:\n\n    1. SOCIAL FRAGMENTATION (0-100%)\n       Does this claim:\n       - Fit into polarizing \"us vs. them\" narratives?\n       - Undermine trust in institutions (government, science, media, elections)?\n       - Deepen societal divisions?\n\n    2. SPURS ACTION (0-100%)\n       Does this claim:\n       - Include explicit or implicit calls to action?\n       - Provide coordination details or targeting information?\n       - Could it motivate harmful real-world behavior?\n\n    3. BELIEVABILITY (0-100%)\n       Is this claim:\n       - Presented in a way that seems credible?\n       - Difficult to refute due to lack of accessible counter-evidence?\n       - Aligned with existing beliefs of target audiences?\n\n    4. EXPLOITATIVENESS (0-100%)\n       Does this claim:\n       - Exploit fear, anger, or other strong emotions?\n       - Target vulnerable populations (elderly, children, marginalized groups)?\n       - Use complexity or jargon to obscure its nature?\n\n    Note: You are assessing POTENTIAL for harm if believed/spread, NOT whether the claim is true or false.\n\n    Analyze the following claim for harm potential:\n    \"{{ claim }}\"\n\n    First, analyze each dimension step by step.\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
    "main.baml": "// BAML Configuration for Explainable ACD\n// Generator and client definitions\n\ngenerator target {\n  output_type \"python/pydantic\"\n  output_dir \"../src/baml_client\"\n  version \"0.215.2\"\n}\n\n// =============================================================================\n// OpenAI Clients\n// =============================================================================\n\nclient<llm> OpenAI_GPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> OpenAI_GPT4o_Short {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n    max_tokens 256\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> OpenAI_GPT4o_Long {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n    max_tokens 512\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> OpenAI_GPT41Mini {\n  provider openai\n  options {\n    model \"gpt-4.1-mini\"\n    api_key env.OPENAI_API_KEY\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> OpenAI_GPT41Mini_Short {\n  provider openai\n  options {\n    model \"gpt-4.1-mini\"\n    api_key env.OPENAI_API_KEY\n    max_tokens 256\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> OpenAI_GPT41Mini_Long {\n  provider openai\n  options {\n    model \"gpt-4.1-mini\"\n    api_key env.OPENAI_API_KEY\n    max_tokens 512\n    logprobs true\n    top_logprobs 5\n  }\n}\n\n// =============================================================================\n// DeepSeek Clients (OpenAI-compatible API)\n// =============================================================================\n\nclient<llm> DeepSeek_V3 {\n  provider openai\n  options {\n    model \"deepseek-chat\"\n    api_key env.DEEPSEEK_API_KEY\n    base_url \"https://api.deepseek.com\"\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> DeepSeek_V3_Short {\n  provider openai\n  options {\n    model \"deepseek-chat\"\n    api_key env.DEEPSEEK_API_KEY\n    base_url \"https://api.deepseek.com\"\n    max_tokens 256\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> DeepSeek_V3_Long {\n  provider openai\n  options {\n    model \"deepseek-chat\"\n    api_key env.DEEPSEEK_API_KEY\n    base_url \"https://api.deepseek.com\"\n    max_tokens 512\n    logprobs true\n    top_logprobs 5\n  }\n}\n\n// =============================================================================\n// xAI Grok Clients (OpenAI-compatible API)\n// =============================================================================\n\nclient<llm> XAI_Grok {\n  provider openai\n  options {\n    model \"grok-4.1\"\n    api_key env.XAI_API_KEY\n    base_url \"https://api.x.ai/v1\"\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> XAI_Grok_Short {\n  provider openai\n  options {\n    model \"grok-4.1\"\n    api_key env.XAI_API_KEY\n    base_url \"https://api.x.ai/v1\"\n    max_tokens 256\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> XAI_Grok_Long {\n  provider openai\n  options {\n    model \"grok-4.1\"\n    api_key env.XAI_API_KEY\n    base_url \"https://api.x.ai/v1\"\n    max_tokens 512\n    logprobs true\n    top_logprobs 5\n  }\n}\n\n// =============================================================================\n// Moonshot Kimi Clients (OpenAI-compatible API)\n// =============================================================================\n\nclient<llm> Moonshot_Kimi {\n  provider openai\n  options {\n    model \"kimi-k2\"\n    api_key env.MOONSHOT_API_KEY\n    base_url \"https://api.moonshot.cn/v1\"\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> Moonshot_Kimi_Short {\n  provider openai\n  options {\n    model \"kimi-k2\"\n    api_key env.MOONSHOT_API_KEY\n    base_url \"https://api.moonshot.cn/v1\"\n    max_tokens 256\n    logprobs true\n    top_logprobs 5\n  }\n}\n\nclient<llm> Moonshot_Kimi_Long {\n  provider openai\n  options {\n    model \"kimi-k2\"\n    api_key env.MOONSHOT_API_KEY\n    base_url \"https://api.moonshot.cn/v1\"\n    max_tokens 512\n    logprobs true\n    top_logprobs 5\n  }\n}\n",
}

def get_baml_files():
    return _file_map